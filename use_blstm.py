import time
import torch 
import numpy as np
from blstm import BLSTM
import matplotlib.pyplot as plt
from model_config import model_hyperparameters
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay


def calc_weight(dataset):
    total = len(dataset)
    weight = [0, 0]
    for _, vul in dataset:
        weight[vul] += 1

    return torch.tensor(list(map(lambda v: total / v, weight)))

class evaluation_metrics(object):
    def __init__(self):
        self.reset()
        
    def reset(self):
        self.confusion_matrix = np.zeros((2,2))
        self.accuracy = 0
        self.precision = 0
        self.recall = 0
        self.f1 = 0
        
    def update(self, confusion_matrix):
        self.confusion_matrix += confusion_matrix
        tn, fp, fn, tp = self.confusion_matrix.ravel()
        self.accuracy = (tp+tn)/(tp+fp+fn+tn)
        self.precision = tp/(fp+tp)
        self.recall = tp/(fn+tp)
        self.f1 = 2 * self.precision * self.recall / (self.precision + self.recall)

    def plot_confusion_matrix(self):
        cm_display = ConfusionMatrixDisplay(self.confusion_matrix, display_labels=[False, True])
        cm_display.plot()
        plt.show()
        
class train_test(object):
    
    def __init__(self, model:BLSTM, config: model_hyperparameters(), file_name):
        self.config = config
        self.epoch = 0
        
        self.model = model
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.optimizer = torch.optim.Adamax(self.model.parameters(), lr=config.learning_rate)
        
        self.train_losses = []
        self.test_losses = []
        
        self.filename = file_name+".pth"
        
    def save(self, state):
        torch.save(state,self.filename)
    
    def load(self, model):
        self.model.load_state_dict(model['state_dict'])
        self.optimizer.load_state_dict(model['optimizer'])
        
    def get_dataloader(self, train_set, test_set):
        train_loader = torch.utils.data.DataLoader(train_set, batch_size=self.config.batch_size, shuffle=False)
        test_loader = torch.utils.data.DataLoader(test_set, batch_size=self.config.batch_size, shuffle=False)
        self.train_loader = train_loader
        self.test_loader = test_loader
        return train_loader, test_loader
    
    def train(self, dataset):
        #set train and test set sizes
        train_size = int(0.7*len(dataset))
        test_size = len(dataset) - train_size
        
        #split dataset into train and test test
        train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])
        
        #get dataloader for train and test sets
        train_loader, test_loader = self.get_dataloader(train_set, test_set)

        self.criterion = torch.nn.CrossEntropyLoss(weight=calc_weight(dataset).to(self.device))
        
        num_epochs = self.config.num_epochs

        start = time.time()
        for epoch in range(num_epochs):
            self.model.train()
            running_loss = 0.0
            for batch_index, (gadget, vul) in enumerate(train_loader):
                gadget = gadget.to(self.device)
                vul = vul.to(self.device)
                self.optimizer.zero_grad()
                out = self.model(gadget)
                loss = self.criterion(out, vul)
                loss.backward()
                self.optimizer.step()
                running_loss += loss.item()
            epoch_loss = running_loss / len(train_loader)
            print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}")
        end = time.time()
        total_time = end-start
        print("Training time: %.2f"%total_time)
        
        #save current state of the model
        state = {'state_dict':self.model.state_dict(), 'optimizer':self.optimizer.state_dict()}
        self.save(state)
        
        #evaluate train and test set
        train_score = self.evaluate(train_loader)
        start = time.time()
        test_score = self.evaluate(test_loader)
        end = time.time()
        total_time = end-start
        print("Prediction time: %.2f"%total_time)
        
        #display graphs
        self.evaluation_graph(train_score, test_score)
        test_score.plot_confusion_matrix()

    def evaluate(self, loader):
        self.model.eval()
        self.load(torch.load(self.filename))
    
        total_score = evaluation_metrics()
        for batch_index, (gadget, vul) in enumerate(loader):
            with torch.no_grad():
                gadget = gadget.to(self.device)
                vul = vul.to(self.device)
                out = self.model(gadget)
                loss = self.criterion(out, vul)
                predicted = torch.max(out.data, dim=1)[1]
                matrix = confusion_matrix(vul.cpu(), predicted.cpu(), labels=[1,0])
                total_score.update(matrix)

        return total_score
            
    def evaluation_graph(self, train_score, test_score):
        x_accuracy = train_score.accuracy
        x_precision = train_score.precision
        x_recall = train_score.recall
        x_f1 = train_score.f1
        y_accuracy = test_score.accuracy
        y_precision = test_score.precision
        y_recall = test_score.recall
        y_f1 = test_score.f1
        
        print("Train set results:")
        print("Accuracy: {:.5f}, Precision: {:.5f}, Recall: {:.5f}, F1-Score: {:.5f}".format(x_accuracy, x_precision, x_recall, x_f1))
        print("Test set results:")
        print("Accuracy: {:.5f}, Precision: {:.5f}, Recall: {:.5f}, F1-Score: {:.5f}".format(y_accuracy, y_precision, y_recall, y_f1))

        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
        train_metrics = [x_accuracy, x_precision, x_recall, x_f1]
        test_metrics = [y_accuracy, y_precision, y_recall, y_f1]
        
        x_labels = np.arange(len(metric_names))
        bar_width=0.35
        fig, ax = plt.subplots()
        train_bars = ax.bar(x_labels - bar_width/2, train_metrics, bar_width, label='Train')
        test_bars = ax.bar(x_labels + bar_width/2, test_metrics, bar_width, label='Test')
        
        # Set the axis labels and title
        ax.set_xlabel('Evaluation Metric')
        ax.set_ylabel('Score')
        ax.set_title('Model Performance on Train and Test Sets')
    
        # Set the x-axis tick labels
        ax.set_xticks(x_labels)
        ax.set_xticklabels(metric_names)
        
        # Add a legend
        ax.legend()
    
        # Show the plot
        plt.show()        
                
            
            
                
            
        
        
        